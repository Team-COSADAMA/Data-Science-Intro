{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs_9EW9fC5cm"
   },
   "source": [
    "### 6. openpyxl 모듈로 웹 크롤링 자료 저장, 읽기 \n",
    "\n",
    "크롤링 했다면 그 결과를 담아야 나중에도 또 쓸 수 있겠죠? 후에 판다스에 연결해서 엑셀을 읽어낼 수도 있구요. 이렇게 엑셀에 담기 위해 필요한 모듈은 openpyxl이라는 것인데요, 아래 코드를 한번만 이해한다면 계속해서 활용하실 수 있을 거에요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6D1JtbFC5cn"
   },
   "outputs": [],
   "source": [
    "# 크롤링 데이터로 엑셀파일 만들기 \n",
    "\n",
    "import openpyxl\n",
    "\n",
    "excel_file = openpyxl.Workbook()\n",
    "excel_file.remove(excel_file.active)\n",
    "excel_sheet = excel_file.create_sheet('안녕 시트')  # sheet 이름 작성 \n",
    "\n",
    "excel_sheet.column_dimensions['B'].width = 150 # column B 크기 정하기 \n",
    "\n",
    "for index in range(9):\n",
    "    excel_sheet.append([index, '안녕']) # 엑셀파일에서 이게 어떻게 구현됐을까요? \n",
    "\n",
    "cell_A1 = excel_sheet['A1']\n",
    "cell_A1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")\n",
    "\n",
    "excel_file.save('test.xlsx')  # 엑셀 파일 이름 설정\n",
    "excel_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDGYiTmPC5co"
   },
   "source": [
    "파일이 저장된 폴더에 가보세요. 그렇다면 test.xlsx 파일이 만들어져 있을 것이랍니다! \n",
    "\n",
    "우리 앞에서 네이버뉴스 타이틀을 추출한 것을 엑셀에다 담아볼까요? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QNpH5g8rC5co"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen \n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "excel_file = openpyxl.Workbook()\n",
    "excel_file.remove(excel_file.active)\n",
    "excel_sheet = excel_file.create_sheet('헤드라인')  # sheet 이름 작성 \n",
    "excel_sheet.column_dimensions['B'].width = 100   # 컬럼 크기 정하기 \n",
    "\n",
    "excel_sheet.append(['번호','제목']) #sheet에 표제목 넣기 \n",
    " \n",
    "import urllib.request # 403 Forbidden 오류해결\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "url = 'https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=105&sid2=731'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "num = 0\n",
    "title = soup.find_all('dt', class_= None)\n",
    "titles=[]\n",
    "for n in title:\n",
    "    a= re.sub('[\\\\n]','',n.get_text())\n",
    "    b= re.sub(\"\\s\\s\\s\\s\\s\\s\\s\\s\",'', a)\n",
    "    titles.append(b)\n",
    "    num += 1\n",
    "    excel_sheet.append([num, b])  # 타이틀 개수와 타이틀 내용\n",
    "\n",
    "\n",
    "cell_A1 = excel_sheet['A1']\n",
    "cell_A1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")  # A1 양식 center로!\n",
    "cell_B1 = excel_sheet['B1']\n",
    "cell_B1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")  # B1 양식 center로!\n",
    "\n",
    "excel_file.save('네이버 뉴스 헤드라인 타이틀 크롤링.xlsx')\n",
    "excel_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "짜잔, 그럼 파일이 저장된 폴더에 가서 엑셀 파일을 열어본다면 네이버 뉴스 모바일 면 1페이지의 뉴스 기사 타이틀이 크롤링 된 것을 확인할 수 있을 겁니다!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
